# This is a spider that collects data rapod7 database
import scrapy,os,sys,re
from web_scraping.items import WebScrapingItem
import unicodedata

import wmi
w = wmi.WMI()

class QuotesSpider(scrapy.Spider):
    results=()
    start_urls=[ 'https://www.rapid7.com/db/?q=']
    for i in w.Win32_Product():
        app = (i.Name)
        if app is not None: 
            app = app.encode('utf-8')
            name = "rapid7"
            start_urls.append('https://www.rapid7.com/db/?q='+str(app))
        

    def parse(self, response):
        item = WebScrapingItem()
        
        name = response.css('.search-query > input:nth-child(1)::attr(value)').get()
        
        for quote in response.css('section.vulndb__results'):
            item['name'] = quote.css('div.resultblock__info-title::text').get() # save the result into item in order to store it in a better csv format
            vul = re.sub('[\W_]+', ' ', str(item)) #remove special characters
            vul = vul[12:] #remove some bad characters at the start of the string
            vul =  vul[:-4] #remove some bad characters at the end of the string
            item['vulnerability']=vul 
            item ['name'] = name
            yield item

            
          

        next_page = response.css('.large-12 > ul:nth-child(1) > li:nth-child(3) > a::attr(href)').get()
  
        if next_page is not None:

            yield response.follow(next_page, callback=self.parse)
       

